{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T12:50:02.074164Z",
     "start_time": "2023-06-13T12:49:58.406153Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tsutsumi/.conda/envs/TFGPU223_20201217/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tsutsumi/.conda/envs/TFGPU223_20201217/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tsutsumi/.conda/envs/TFGPU223_20201217/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tsutsumi/.conda/envs/TFGPU223_20201217/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tsutsumi/.conda/envs/TFGPU223_20201217/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tsutsumi/.conda/envs/TFGPU223_20201217/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "## Libraries need to calculate Moprho-VAE\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import cv2  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from functions import *\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035e336c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T12:50:03.251938Z",
     "start_time": "2023-06-13T12:50:02.081468Z"
    }
   },
   "outputs": [],
   "source": [
    "## GPU settings \n",
    "## This code is written in Tensorflow v1\n",
    "### if you want to run this notebook, you should prepare GPU.\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"0\", # specify GPU number\n",
    "        allow_growth=True\n",
    "    )\n",
    ")\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b64b7",
   "metadata": {},
   "source": [
    "# Load images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06121778",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T12:50:04.274652Z",
     "start_time": "2023-06-13T12:50:03.259915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size :(195, 128, 128, 3), Test size:(99, 128, 128, 3)\n",
      "Train2 size :(145, 128, 128, 3), val size:(50, 128, 128, 3)\n",
      "42\n",
      "train\n",
      "['PRICT-998' 'PRICT-998' 'PRICT-990' 'PRICT-990' 'PRICT-1270' 'PRICT-1270'\n",
      " 'PRICT-1266' 'PRICT-1266' 'PRICT-1264' 'PRICT-1264' 'PRICT-1256'\n",
      " 'PRICT-1256' 'PRICT-1252' 'PRICT-1252' 'PRICT-1244' 'PRICT-1244'\n",
      " 'PRICT-1242' 'PRICT-1242' 'PRICT-1238' 'PRICT-1238' 'PRICT-1141'\n",
      " 'PRICT-1141' 'PRICT-1135' 'PRICT-1135' 'PRICT-1133' 'PRICT-1133'\n",
      " 'PRICT-1098' 'PRICT-1098' 'PRICT-1062' 'PRICT-1062' 'PRICT-1054'\n",
      " 'PRICT-1054' 'PRICT-1053' 'PRICT-1053' 'PRICT-1009' 'PRICT-1009'\n",
      " 'PRICT-1008' 'PRICT-1008' 'PRICT-1006' 'PRICT-1006'\n",
      " 'Mandrillus_leucophaeus_mandible_23169'\n",
      " 'Mandrillus_leucophaeus_mandible_23169'\n",
      " 'Mandrillus_leucophaeus_mandible_23168'\n",
      " 'Mandrillus_leucophaeus_mandible_23168'\n",
      " 'Mandrillus_leucophaeus_mandible_20085'\n",
      " 'Mandrillus_leucophaeus_mandible_20085'\n",
      " 'Mandrillus_leucophaeus_mandible_19986'\n",
      " 'Mandrillus_leucophaeus_mandible_19986' 'M9754' 'M9754' 'M9244' 'M9244'\n",
      " 'M13644' 'M13644' 'M13642' 'M13642' 'M13639' 'M13639' 'M13480' 'M13480'\n",
      " 'M13472' 'M13472' 'M13471' 'M13471' 'M13468' 'M13468' 'M13466' 'M13466'\n",
      " 'M13463' 'M13463' 'M13269' 'M13269' 'M13094' 'M13094' 'M12320' 'M12320'\n",
      " 'M12315' 'M12315' 'M12308' 'M12308' 'M12290' 'M12290' 'M12289' 'M12289'\n",
      " 'M12286' 'M12286' 'M12255' 'M12255' 'M12229' 'M12229' 'M12224' 'M12224'\n",
      " 'M12221' 'M12221' 'M12219' 'M12219' 'M12261' 'M12261' 'M12062' 'M12062'\n",
      " 'M12061' 'M12061' 'M12060' 'M12060' 'M12059' 'M12059' 'M12058' 'M12058'\n",
      " 'M12057' 'M12057' 'M12053' 'M12053' 'M12050' 'M12050' 'M12042' 'M12042'\n",
      " 'PRICT-1069' 'PRICT-1069' 'PRICT-1066' 'PRICT-1066' 'Dokkyo_2632'\n",
      " 'Dokkyo_2632' 'Dokkyo_2326' 'Dokkyo_2326' 'M3219' 'M3219' 'M13091'\n",
      " 'M13091' 'M2978' 'M2978' 'Eulemur_mongoz_PRI5378'\n",
      " 'Eulemur_mongoz_PRI5378' 'M58765' 'M44761' 'M44761' 'M3131' 'M3131'\n",
      " 'M26593' 'M26593' 'Dokkyo_4057' 'Dokkyo_4057' 'Dokkyo_3268' 'Dokkyo_3268'\n",
      " 'Dokkyo_2364' 'Dokkyo_2364' 'Dokkyo_1696' 'Dokkyo_1696' 'M213' 'M213'\n",
      " 'M151' 'M151' 'M100' 'M100' 'M092' 'M092' 'M056' 'M056' 'M040' 'M040'\n",
      " 'M021' 'M021' 'M020' 'M020' 'M015' 'M015' 'M014' 'M014' 'M008' 'M008'\n",
      " 'M006' 'M006' 'M005' 'M005' 'M002' 'M002' 'Gorilla_mandible_38326'\n",
      " 'Gorilla_mandible_38326' 'Gorilla_mandible_37265'\n",
      " 'Gorilla_mandible_37265' 'Gorilla_mandible_26850'\n",
      " 'Gorilla_mandible_26850' 'Dokkyo_5011' 'Dokkyo_5011' 'Dokkyo_2763'\n",
      " 'Dokkyo_2763' 'Dokkyo_0218' 'Dokkyo_0218' 'M42028' 'M42028' 'M42026'\n",
      " 'M42026' 'M42024' 'M42024' 'M42022' 'M42022']\n",
      "test\n",
      "['PRICT-994' 'PRICT-994' 'PRICT-1272' 'PRICT-1272' 'PRICT-1268'\n",
      " 'PRICT-1268' 'PRICT-1262' 'PRICT-1262' 'PRICT-1260' 'PRICT-1260'\n",
      " 'PRICT-1254' 'PRICT-1254' 'PRICT-1139' 'PRICT-1139' 'PRICT-1094'\n",
      " 'PRICT-1094' 'PRICT-1051' 'PRICT-1051' 'M9247' 'M9247' 'M13627' 'M13627'\n",
      " 'M13624' 'M13624' 'M13482' 'M13482' 'M13464' 'M13464' 'M13100' 'M13100'\n",
      " 'M13098' 'M13098' 'M13095' 'M13095' 'M13092' 'M13092' 'M13088' 'M13088'\n",
      " 'M13087' 'M13087' 'M12307' 'M12307' 'M12287' 'M12287' 'M12257' 'M12257'\n",
      " 'M12250' 'M12250' 'M12226' 'M12226' 'M12063' 'M12063' 'M12056' 'M12055'\n",
      " 'M12052' 'M12052' 'M10765' 'M10765' 'Dokkyo_1811' 'Dokkyo_1811'\n",
      " 'Dokkyo_0100' 'Dokkyo_0100' 'Dokkyo_2715' 'Dokkyo_2715' 'Dokkyo_2436'\n",
      " 'Dokkyo_2436' 'M58766' 'Dokkyo_1073' 'Dokkyo_1073' 'Dokkyo_0649'\n",
      " 'Dokkyo_0649' 'Dokkyo_1452' 'Dokkyo_1452' 'Dokkyo_1267' 'Dokkyo_1267'\n",
      " 'M292' 'M292' 'M107' 'M107' 'M096' 'M096' 'M042' 'M042' 'M035' 'M035'\n",
      " 'M012' 'M012' 'Gorilla_mandible_14750' 'Gorilla_mandible_14750'\n",
      " 'Dokkyo_9004' 'Dokkyo_9004' 'Dokkyo_4095' 'Dokkyo_4095' 'Dokkyo_1755'\n",
      " 'Dokkyo_1755' 'M42020' 'M42020' 'M42017' 'M42017']\n",
      "val\n",
      "['PRICT-990' 'PRICT-990' 'PRICT-1266' 'PRICT-1266' 'PRICT-1252'\n",
      " 'PRICT-1252' 'PRICT-1133' 'PRICT-1133' 'PRICT-1054' 'PRICT-1054'\n",
      " 'PRICT-1006' 'PRICT-1006' 'M9244' 'M9244' 'M13639' 'M13639' 'M13471'\n",
      " 'M13471' 'M12315' 'M12315' 'M12308' 'M12308' 'M12224' 'M12224' 'M12221'\n",
      " 'M12221' 'M12058' 'M12058' 'M12053' 'M12053' 'Dokkyo_2632' 'Dokkyo_2632'\n",
      " 'M13091' 'M13091' 'M3131' 'M3131' 'Dokkyo_2364' 'Dokkyo_2364' 'M213'\n",
      " 'M213' 'M092' 'M092' 'M056' 'M056' 'Gorilla_mandible_38326'\n",
      " 'Gorilla_mandible_38326' 'Gorilla_mandible_37265'\n",
      " 'Gorilla_mandible_37265' 'M42024' 'M42024']\n"
     ]
    }
   ],
   "source": [
    "# load figures \n",
    "X, y = load_data()\n",
    "filelist = pd.read_csv(\"./new_Mandible_check.csv\", encoding=\"SHIFT-JIS\")\n",
    "\n",
    "\n",
    "test_seed = 230\n",
    "val_seed = 42\n",
    "## Split data into train and test data.\n",
    "X_train, y_train,Y_train, X_test, y_test , Y_test, group_train, group_test =  make_train_test(X,y,seed = test_seed)\n",
    "## Split train data into val  and train data\n",
    "X_train_2, y_train_2,Y_train_2, X_val, y_val ,Y_val, val_seed, group_train_2, group_val = \\\n",
    "make_val_train(X_train,y_train,group_train,seed = val_seed)\n",
    "print(val_seed)\n",
    "\n",
    "num_to_name ={0: 'Cercopithecidae',\n",
    " 1: 'Cebidae',\n",
    " 2: 'Lemuridae',\n",
    " 3: 'Atelidae',\n",
    " 4: 'Hylobatidae',\n",
    " 5: 'Homonidae',\n",
    " 6: 'Phocidae'}\n",
    "\n",
    "y_name= np.array(pd.Series(y).replace(num_to_name))\n",
    "\n",
    "\n",
    "print(\"train\")\n",
    "print(group_train)\n",
    "print(\"test\")\n",
    "print(group_test) \n",
    "print(\"val\")\n",
    "print(group_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfdd096",
   "metadata": {},
   "source": [
    "# Model setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0357e27a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T12:50:10.205302Z",
     "start_time": "2023-06-13T12:50:09.104701Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vae_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ec5baeb6b26a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0march_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m model.compile(optimizer=optimizer, \n\u001b[0;32m---> 18\u001b[0;31m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvae_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m           \u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m           metrics=['accuracy'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vae_loss' is not defined"
     ]
    }
   ],
   "source": [
    "### Model setting \n",
    "####  this csv file includes 10 tuned models.\n",
    "#### Best model is 7-th model. \n",
    "arch_list = pd.read_csv('./architecture_list.csv')\n",
    "num = 7\n",
    "### ration of Reconstruction loss and Classification losss\n",
    "### in this paper we set alpha = 0.1\n",
    "## If you set alpha = 0 this matches VAE. \n",
    "alpha = 0.1 \n",
    "### the dimension of latent space Î¶\n",
    "latent_dim = 3\n",
    "\n",
    "### create Morpho-VAE model\n",
    "model, z_mean, z_log_var, encoder, decoder, Classifier = create_model(arch_list.iloc[num,0], arch_list.iloc[num,1], list((arch_list.iloc[num,2:7]).astype(int)),3)\n",
    "\n",
    "optimizer = arch_list.iloc[num,8]\n",
    "model.compile(optimizer=optimizer, \n",
    "          loss = ['categorical_crossentropy',], \n",
    "          loss_weights = [alpha, 1 - alpha],\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load Morpho-VAE's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T12:45:47.106077Z",
     "start_time": "2023-06-13T12:45:47.084964Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e0fba6c1332c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./WEIGHTS/Publish/*/{0}/model_*\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifier_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "## We load the weights of Morpho-VAE.\n",
    "## If you want to train Morpho-VAE, ignore this cell and move to 2.2 train model section.\n",
    "test_seed = 230\n",
    "val_seed = 42\n",
    "\n",
    "    \n",
    "encoder_path = glob.glob(\"./WEIGHTS/Publish/*/{0}/encoder_*\".format(test_seed))[0]\n",
    "decoder_path = glob.glob(\"./WEIGHTS/Publish/*/{0}/decoder_*\".format(test_seed))[0]\n",
    "Classifier_path = glob.glob(\"./WEIGHTS/Publish/*/{0}/Classifier_*\".format(test_seed))[0]\n",
    "model_path = glob.glob(\"./WEIGHTS/Publish/*/{0}/model_*\".format(test_seed))[0]\n",
    "\n",
    "encoder.load_weights(encoder_path)\n",
    "decoder.load_weights(decoder_path)\n",
    "Classifier.load_weights(Classifier_path)\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load VAE's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## VAE\n",
    "test_seed = 227\n",
    "\n",
    "arch_list = pd.read_csv('/home/tsutsumi/BONE/MORPHO-VAE/CODE/architecture_list.csv')\n",
    "num = 4\n",
    "\n",
    "VAE_model, z_mean, z_log_var, VAE_encoder, VAE_decoder, VAE_Classifier = create_model(arch_list.iloc[num,0], arch_list.iloc[num,1], list((arch_list.iloc[num,2:7]).astype(int)),3)\n",
    "\n",
    "\n",
    "encoder_path = glob.glob(\"./WEIGHTS/Publish/20220211/{0}/encoder_*\".format(test_seed))[0]\n",
    "decoder_path = glob.glob(\".WEIGHTS/Publish/20220211/{0}/decoder_*\".format(test_seed))[0]\n",
    "Classifier_path = glob.glob(\"./WEIGHTS/Publish/20220211/{0}/Classifier_*\".format(test_seed))[0]\n",
    "model_path = glob.glob(\"./WEIGHTS/Publish/20220211/{0}/model_*\".format(test_seed))[0]\n",
    "\n",
    "VAE_encoder.load_weights(encoder_path)\n",
    "VAE_decoder.load_weights(decoder_path)\n",
    "VAE_Classifier.load_weights(Classifier_path)\n",
    "VAE_model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that if you want to train Morpho-VAE model, GPU enviroments is needed.\n",
    "CPU environments will cost you a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_2,\n",
    "                      [Y_train_2, X_train_2],\n",
    "                      epochs=100,\n",
    "                      batch_size=10,\n",
    "                      validation_data=(X_val,[Y_val,X_val]),\n",
    "                      callbacks = callbacks,\n",
    "                     verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Morpho-VAE\n",
    "X_predict_morphoVAE = encoder.predict(X)\n",
    "plot_3d(X_predict_morphoVAE, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VAE\n",
    "X_predict_VAE = VAE_encoder.predict(X)\n",
    "plot_3d(X_predict_VAE, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA\n",
    "d1, d2, d3, d4 = X.shape\n",
    "X_flatten = X.reshape((d1, -1))\n",
    "pca = PCA(n_components=3, svd_solver='arpack')\n",
    "pca.fit(X_flatten)\n",
    "feature = pca.transform(X_flatten)\n",
    "\n",
    "plot_3d(feature, y_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructiong and Generating Images from Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The value of PC3\n",
    "zi = 0\n",
    "## The size of rectangle\n",
    "size = 10\n",
    "\n",
    "x_predict = X_predict_morphoVAE.copy()\n",
    "xyz = np.mean(x_predict, axis = 0)[:,np.newaxis]+ zi * pca.components_[2][:,np.newaxis] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## latent space and PCA plane\n",
    "plot_latent_and_PCAplane(x_predict, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA plane\n",
    "pca = PCA()\n",
    "feature = pca.fit(x_predict)\n",
    "feature = pca.transform(x_predict)\n",
    "\n",
    "plot_2d(feature,y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reconst grid images\n",
    "reconst_grid_images(size,xyz,digit_size = 128,THR = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Explanation of the Basis for Class Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,10))\n",
    "for family_num in [5]:\n",
    "    for idx in range(np.where([y_test == family_num])[1].shape[0]):\n",
    "        Num = np.where([y_test == family_num])[1][idx]\n",
    "        family = sorted(set(y_name))[np.argmax(Y_train[Num])]\n",
    "        for color,i,ch in zip(['G','B','R'],[0,1,2],[1,2,0]):\n",
    "            ax = fig.add_subplot(np.where([y_test == family_num])[1].shape[0], 3, idx * 3+i +1)\n",
    "            ax.axes.xaxis.set_visible(False)\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "            x, A,act_map = score_cam(num = Num , layer_name = '{}_conv_4'.format(color))\n",
    "            A = cv2.resize(A,(128,128))\n",
    "            A = np.maximum(A, 0)     \n",
    "            A /= np.max(A)      \n",
    "            ax.imshow(A,cmap='GnBu')\n",
    "            ax.imshow(x[0,:,:,ch], alpha = 0.1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction from Cropped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'M012'\n",
    "size = 25\n",
    "\n",
    "NAME = '{}.png'.format(name)\n",
    "CROPPED = '../Fixed_figure/Crop_fig_{}/RGB/{}'.format(size,NAME)\n",
    "NOT_CROPPED = '../New-RGB/{}'.format(NAME)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(cv2.imread(NOT_CROPPED))\n",
    "plt.subplot(132)\n",
    "plt.imshow(cv2.imread(CROPPED))\n",
    "plt.subplot(133)\n",
    "plt.imshow(decoder.predict(encoder.predict(cv2.imread(CROPPED)[np.newaxis]/255))[0])\n",
    "print(\"True: {} , Predict: {}\".format(y_test[group_test == name][0],np.argmax(Classifier.predict(cv2.imread(CROPPED)[np.newaxis]/255))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TFGPU223_20201217]",
   "language": "python",
   "name": "conda-env-TFGPU223_20201217-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
