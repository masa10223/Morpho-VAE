{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T12:31:31.253538Z",
     "start_time": "2021-12-13T12:31:31.215505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tsutsumi/anaconda3/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import optuna\n",
    "\n",
    "import cv2  # 画像認識するのはcv2\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.backend import set_session\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "## Tensorflow-v2 の場合。\n",
    "\n",
    "### TensorFlow 2 で 1.x のコードを走らせるには\n",
    "tf.compat.v1.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Optuna 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T19:11:24.113982Z",
     "start_time": "2020-12-13T19:11:21.634Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    path_dir = \"../New-RGB/\"\n",
    "\n",
    "    filelist = pd.read_csv(\"./new_Mandible_check.csv\", encoding=\"SHIFT-JIS\")\n",
    "    #filelist.columns = [\"num\",\"Filename\", \"Species\", \"Japanese\"]\n",
    "    japanese_group = filelist.groupby([\"Japanese\"])\n",
    "    FILELIST = filelist.sort_values(\"Filename\")\n",
    "    japanese_file = list(FILELIST.Japanese)\n",
    "    \n",
    "    num_list = []\n",
    "\n",
    "    for i,_ in filelist.iterrows():\n",
    "            num_list.append(i)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    y_jap = []\n",
    "    y_species = []\n",
    "    y_food = []\n",
    "    filelise_index = []\n",
    "    for i in num_list:\n",
    "        PATH = os.path.join(*[path_dir, filelist.Filename[i]])\n",
    "        if os.path.isfile(PATH) == True:\n",
    "            img = cv2.imread(PATH)\n",
    "            #img = cv2.resize(img, (128,128))\n",
    "            img = img /255\n",
    "            X.append(img)\n",
    "            y.append(filelist.Family_num[i])\n",
    "            y_jap.append(filelist.Family[i])\n",
    "            y_species.append(filelist.Japanese[i])\n",
    "            y_food.append(filelist.Food[i])\n",
    "        else:\n",
    "            print(PATH)\n",
    "        \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Composition of Data.\n",
    "    \n",
    "    data ━━━┳━━> train 67 % ┳━━ train  75 %\n",
    "            ┃               ┗━━   val  25 %\n",
    "            ┃\n",
    "            ┗-- test  33 %\n",
    "    \n",
    "    test data ... data for check accuracy, loss et al\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def make_train_test(X,y,seed = 223):\n",
    "\n",
    "    X_test =[]\n",
    "    y_test =[]\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    group_train = []\n",
    "        \n",
    "    filelist = pd.read_csv(\"./new_Mandible_check.csv\", encoding=\"SHIFT-JIS\")\n",
    "    #filelist.columns = [\"num\",\"Filename\", \"Species\", \"Japanese\"]\n",
    "    for i in range(7):\n",
    "        Group = filelist[y == i].Tag\n",
    "        yy = y[y == i]\n",
    "        #yyy = y_tag[y ==i]\n",
    "        XX = X[y==i]\n",
    "        gss = GroupShuffleSplit(n_splits=2, train_size=.67, random_state=seed)\n",
    "        for train_idx, test_idx in gss.split(XX, yy, Group):\n",
    "            continue\n",
    "        #print(yyy[test_idx])\n",
    "        X_test.append(XX[test_idx])\n",
    "        X_train.append(XX[train_idx])\n",
    "        y_test.append(yy[test_idx])\n",
    "        y_train.append(yy[train_idx])\n",
    "        group_train.append(np.array(Group)[train_idx])\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    group_train = np.array(group_train)\n",
    "\n",
    "    for j in range(X_train.shape[0]):\n",
    "        if j == 0 :\n",
    "            tmp = X_train[j]\n",
    "            tmp2 = y_train[j]\n",
    "            tmp3 = group_train[j]\n",
    "        else:\n",
    "            tmp = np.concatenate([tmp, X_train[j]])\n",
    "            tmp2 = np.concatenate([tmp2,y_train[j]])\n",
    "            tmp3 = np.concatenate([tmp3,group_train[j]])\n",
    "    X_train = tmp\n",
    "    y_train = tmp2\n",
    "    group_train = tmp3\n",
    "\n",
    "    for j in range(X_test.shape[0]):\n",
    "        if j == 0 :\n",
    "            tmp = X_test[j]\n",
    "            tmp2 = y_test[j]\n",
    "        else:\n",
    "            tmp = np.concatenate([tmp, X_test[j]])\n",
    "            tmp2 = np.concatenate([tmp2,y_test[j]])\n",
    "    X_test = tmp\n",
    "    y_test = tmp2\n",
    "    print(\"Train size :{}, Test size:{}\".format(np.array(X_train).shape,np.array(X_test).shape))\n",
    "    Y_train = to_categorical(y_train)\n",
    "    Y_test = to_categorical(y_test)\n",
    "\n",
    "    return X_train, y_train,Y_train, X_test, y_test ,Y_test, group_train\n",
    "\n",
    "seed = 42\n",
    "\n",
    "def make_val_train(X_train,y_train,group_train, seed = seed):\n",
    "    X_val =[]\n",
    "    y_val =[]\n",
    "    X_train_2 = []\n",
    "    y_train_2 = []\n",
    "    for i in range(7):\n",
    "        Group = group_train[y_train == i]\n",
    "        yy = y_train[y_train == i]\n",
    "        #yyy = y_tag[y ==i]\n",
    "        XX = X_train[y_train==i]\n",
    "        gss = GroupShuffleSplit(n_splits=2, train_size=.75, random_state=seed)\n",
    "        for train_idx, test_idx in gss.split(XX, yy, Group):\n",
    "            continue\n",
    "        #print(yyy[test_idx])\n",
    "        X_val.append(XX[test_idx])\n",
    "        X_train_2.append(XX[train_idx])\n",
    "        y_val.append(yy[test_idx])\n",
    "        y_train_2.append(yy[train_idx])\n",
    "        \n",
    "    X_train_2 = np.array(X_train_2)\n",
    "    X_val = np.array(X_val)\n",
    "    \n",
    "    for j in range(X_train_2.shape[0]):\n",
    "            if j == 0 :\n",
    "                tmp = X_train_2[j]\n",
    "                tmp2 = y_train_2[j]\n",
    "            else:\n",
    "                tmp = np.concatenate([tmp, X_train_2[j]])\n",
    "                tmp2 = np.concatenate([tmp2,y_train_2[j]])\n",
    "    X_train_2 = tmp\n",
    "    y_train_2 = tmp2\n",
    "    \n",
    "    for j in range(X_val.shape[0]):\n",
    "        if j == 0 :\n",
    "            tmp =X_val[j]\n",
    "            tmp2 = y_val[j]\n",
    "        else:\n",
    "            tmp = np.concatenate([tmp, X_val[j]])\n",
    "            tmp2 = np.concatenate([tmp2,y_val[j]])\n",
    "    X_val = tmp\n",
    "    y_val = tmp2\n",
    "\n",
    "    Y_train_2 = to_categorical(y_train_2)\n",
    "    Y_val = to_categorical(y_val)\n",
    "    print(\"Train2 size :{}, val size:{}\".format(np.array(X_train_2).shape,np.array(X_val).shape))\n",
    "    \n",
    "    return X_train_2, y_train_2,Y_train_2, X_val, y_val ,Y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T19:11:24.127917Z",
     "start_time": "2020-12-13T19:11:23.482Z"
    },
    "code_folding": [
     24,
     30,
     36
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_model(num_layer, activation, num_filters, latent_dim = 3):\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean =0., stddev =1.)\n",
    "        return z_mean + K.exp(z_log_var) * epsilon\n",
    "    \n",
    "    def vae_loss(inputs, z_decoded):\n",
    "        x = K.flatten(inputs)\n",
    "        z_decoded = K.flatten(z_decoded)\n",
    "        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
    "        kl_loss = -5e-4 * K.mean(\n",
    "            1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "   \n",
    "    inputs = Input((128,128,3))\n",
    "\n",
    "    x0 = Lambda(lambda x: x[ :,:,:,0:1], output_shape=(128,128,1),name = 'R_extract')(inputs)\n",
    "    x1 = Lambda(lambda x: x[ :,:,:,1:2], output_shape=(128,128,1),name = 'G_extract')(inputs)\n",
    "    x2 = Lambda(lambda x: x[:,:,:,2:], output_shape=(128,128,1),name = 'B_extract')(inputs)\n",
    "\n",
    "    x0 = Convolution2D(filters=num_filters[0], kernel_size=(3,3), padding=\"same\", activation=activation,\n",
    "                      name = 'R_input')(x0)\n",
    "    #print(K.int_shape(x0))\n",
    "    for i in range(1,num_layer):\n",
    "        x0 = MaxPooling2D((2,2), padding='same', name = 'R_MaxPool_{}'.format(i))(x0)\n",
    "        x0 = Convolution2D(filters=num_filters[i], kernel_size=(3,3), padding=\"same\", activation=activation,\n",
    "                          name = 'R_conv_{}'.format(i))(x0)\n",
    "    x0 = layers.Flatten(name = 'R_flatten')(x0)\n",
    "\n",
    "    x1 = Convolution2D(filters=num_filters[0], kernel_size=(3,3), padding=\"same\", activation=activation,\n",
    "                      name = 'G_input')(x1)\n",
    "    for i in range(1,num_layer):\n",
    "        x1 = MaxPooling2D((2,2), padding='same',name = 'G_MaxPool_{}'.format(i))(x1)\n",
    "        x1 = Convolution2D(filters=num_filters[i], kernel_size=(3,3), padding=\"same\", activation=activation\n",
    "                          ,name = 'G_conv_{}'.format(i))(x1)\n",
    "    x1 = layers.Flatten(name = 'G_flatten')(x1)\n",
    "\n",
    "    x2 = Convolution2D(filters=num_filters[0], kernel_size=(3,3), padding=\"same\", activation=activation,\n",
    "                      name = 'B_input')(x2)\n",
    "    for i in range(1,num_layer):\n",
    "        x2 = MaxPooling2D((2,2), padding='same',name = 'B_MaxPool_{}'.format(i))(x2)\n",
    "        x2 = Convolution2D(filters=num_filters[i], kernel_size=(3,3), padding=\"same\", activation=activation\n",
    "                          ,name = 'B_conv_{}'.format(i))(x2)\n",
    "    x2 = layers.Flatten(name = 'B_flatten')(x2)\n",
    "\n",
    "    x = keras.layers.Concatenate(name = 'Concatenate')([x0, x1, x2])\n",
    "    shape_before_flattening = K.int_shape(x)\n",
    "\n",
    "\n",
    "    ## Intermediate Layer Part\n",
    "    z_mean = layers.Dense(latent_dim, name ='z_mean')(x) #latent Spaceに圧縮\n",
    "    z_log_var = layers.Dense(latent_dim, name ='z_log_var')(x) #z_sigma に対応している\n",
    "    z = layers.Lambda(sampling, name = 'sampling')([z_mean, z_log_var])\n",
    "\n",
    "    encoder = Model(inputs,z)\n",
    "\n",
    "    decoder_input = layers.Input(K.int_shape(z)[1:])\n",
    "    x = layers.Dense(np.prod(shape_before_flattening[1:]),activation=activation)(decoder_input)\n",
    "\n",
    "    Shape = int(128 /(2 ** (num_layer - 1)))\n",
    "    flatten_shape = int(Shape * Shape * num_filters[-1])\n",
    "\n",
    "    ## 実質的な Convolution\n",
    "    x0 = Lambda(lambda x: x[:, :flatten_shape], output_shape=(Shape,Shape,num_filters[-1]))(x)\n",
    "    x1 = Lambda(lambda x: x[:,  flatten_shape:2 * flatten_shape], output_shape=(Shape,Shape,num_filters[-1]))(x)\n",
    "    x2 = Lambda(lambda x: x[:, 2*flatten_shape:], output_shape=(Shape,Shape,num_filters[-1]))(x)\n",
    "\n",
    "    x0 =layers.Reshape((Shape, Shape, num_filters[-1]))(x0)\n",
    "    x1 =layers.Reshape((Shape, Shape, num_filters[-1]))(x1)\n",
    "    x2 =layers.Reshape((Shape, Shape, num_filters[-1]))(x2)\n",
    "\n",
    "    for i in reversed(range(num_layer - 1)):\n",
    "            x0 = Convolution2D(filters=num_filters[i], kernel_size=(3,3),padding=\"same\", activation=activation)(x0)\n",
    "            x0 = UpSampling2D((2,2))(x0)\n",
    "    x0 = Convolution2D(1,(3,3), padding='same', activation='sigmoid')(x0)\n",
    "\n",
    "    for i in reversed(range(num_layer - 1)):\n",
    "            x1 = Convolution2D(filters=num_filters[i], kernel_size=(3,3),padding=\"same\", activation=activation)(x1)\n",
    "            x1 = UpSampling2D((2,2))(x1)\n",
    "    x1 = Convolution2D(1,(3,3), padding='same', activation='sigmoid')(x1)\n",
    "\n",
    "    for i in reversed(range(num_layer - 1)):\n",
    "            x2 = Convolution2D(filters=num_filters[i], kernel_size=(3,3),padding=\"same\", activation=activation)(x2)\n",
    "            x2 = UpSampling2D((2,2))(x2)\n",
    "    x2 = Convolution2D(1,(3,3), padding='same', activation='sigmoid')(x2)\n",
    "\n",
    "    decoder_output = layers.Concatenate()([x0, x1, x2])\n",
    "    decoder = Model(decoder_input, decoder_output)\n",
    "    z_decoded = decoder(z)\n",
    "\n",
    "    classification_output = layers.Dense(7 ,activation='softmax',name = 'Family_Classifier')(z)\n",
    "\n",
    "    model = Model(inputs, [classification_output, z_decoded])\n",
    "\n",
    "    Classifier = Model(inputs,classification_output, name ='Classifier')\n",
    "    \n",
    "    return model, z_mean, z_log_var, encoder, decoder, Classifier\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    alpha = 0.5\n",
    "    latent_dim = 3\n",
    "\n",
    "    #セッションのクリア\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    def vae_loss(inputs, z_decoded):\n",
    "        x = K.flatten(inputs)\n",
    "        z_decoded = K.flatten(z_decoded)\n",
    "        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
    "        kl_loss = -5e-4 * K.mean(\n",
    "            1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "    \n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\"./WEIGHTS/optuna_tmp_33.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=0)\n",
    "\n",
    "    earlystop = keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                              min_delta = 0, \n",
    "                              patience = 10,\n",
    "                              verbose = 0)\n",
    "\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                  factor = 0.5,\n",
    "                                  patience = 10,\n",
    "                                  verbose = 0)\n",
    "\n",
    "    callbacks = [earlystop, checkpoint, reduce_lr]\n",
    "    \n",
    "\n",
    "    #最適化するパラメータの設定\n",
    "    #畳込み層の数\n",
    "    num_layer = trial.suggest_int(\"num_layer\", 1,5)\n",
    "\n",
    "    #latent_dim = trial.suggest_int(\"latent_dim\", 2,5)\n",
    "\n",
    "    #各畳込み層のフィルタ数\n",
    "    num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n",
    "\n",
    "    #活性化関数\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"sigmoid\", \"tanh\"])\n",
    "\n",
    "    #optimizer\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"adam\", \"rmsprop\"])\n",
    "\n",
    "    model, z_mean, z_log_var, encoder, decoder, Classifier = create_model(num_layer, activation, num_filters,latent_dim)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss = ['categorical_crossentropy',vae_loss], \n",
    "                  loss_weights = [alpha, 1-alpha],\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    X_train, y_train,Y_train, X_test, y_test , Y_test, group_train =  make_train_test(X,y)\n",
    "    \n",
    "    X_train_2, y_train_2,Y_train_2, X_val, y_val ,Y_val = make_val_train(X_train,y_train,group_train,seed = 42)\n",
    "    \n",
    "    history = model.fit(X_train_2,\n",
    "                        [Y_train_2, X_train_2],\n",
    "                        epochs=100,\n",
    "                        batch_size=10,\n",
    "                        validation_data=(X_val,[Y_val,X_val]),\n",
    "                        callbacks = callbacks,\n",
    "                        verbose = 2)\n",
    "    os.makedirs('./WEIGHTS',exist_ok=True)\n",
    "    date = '20220202'\n",
    "    os.makedirs('./WEIGHTS/{}'.format(date), exist_ok=True)\n",
    "    \n",
    "    encoder.save_weights('./WEIGHTS/{0}/encoder_{0}_alpha{1}_index{2}_seed{3}.h5'.format(date,alpha, index,seed))\n",
    "    decoder.save_weights('./WEIGHTS/{0}/decoder_{0}_alpha{1}_index{2}_seed{3}.h5'.format(date,alpha, index,seed))\n",
    "    Classifier.save_weights('./WEIGHTS/{0}/Classifier_{0}_alpha{1}_index{2}_seed{3}.h5'.format(date,alpha, index,seed))\n",
    "    model.save_weights('./WEIGHTS/{0}/model_{0}_alpha{1}_index{2}_seed{3}.h5'.format(date,alpha, index,seed))\n",
    "    \n",
    "    ## 実際に Lossなどを計算する。\n",
    "    test_loss, test_reconst_loss, test_class_loss, test_reconst_acc, test_class_acc = model.evaluate(X_test,[Y_test, X_test])\n",
    "    print(test_loss, test_reconst_loss, test_class_loss, test_reconst_acc, test_class_acc)\n",
    "    # clear the data to relaese the memory\n",
    "    del  X_train, y_train,Y_train, X_test, y_test , Y_test, X_train_2, y_train_2, Y_train_2, X_val, y_val, Y_val\n",
    "    import re \n",
    "    pattern = '.*?(\\d+).*'\n",
    "    s = str(history.history.keys())\n",
    "    number = int(re.findall(r'\\d+', s)[0])\n",
    "\n",
    "    return history.history[\"val_loss\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89909/1736647027.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array(X_train)\n",
      "/tmp/ipykernel_89909/1736647027.py:82: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test = np.array(X_test)\n",
      "/tmp/ipykernel_89909/1736647027.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  group_train = np.array(group_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size :(194, 128, 128, 3), Test size:(100, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train,Y_train, X_test, y_test , Y_test, group_train =  make_train_test(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train2 size :(144, 128, 128, 3), val size:(50, 128, 128, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89909/1736647027.py:132: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train_2 = np.array(X_train_2)\n",
      "/tmp/ipykernel_89909/1736647027.py:133: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_val = np.array(X_val)\n"
     ]
    }
   ],
   "source": [
    "X_train_2, y_train_2,Y_train_2, X_val, y_val ,Y_val = make_val_train(X_train,y_train,group_train, seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 15:22:59,303]\u001b[0m A new study created in memory with name: no-name-c4972763-5ae7-49ec-8e9c-cea8ad1b4fb1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th trial\n",
      "Train size :(194, 128, 128, 3), Test size:(100, 128, 128, 3)\n",
      "Train2 size :(144, 128, 128, 3), val size:(50, 128, 128, 3)\n",
      "Train on 144 samples, validate on 50 samples\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 15:23:01.125983: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-03 15:23:03.513539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4094 MB memory:  -> device: 0, name: GeForce RTX 3090, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
      "2022-02-03 15:23:03.515609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 4096 MB memory:  -> device: 1, name: GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\n",
      "2022-02-03 15:23:03.516768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 21882 MB memory:  -> device: 2, name: GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2022-02-03 15:23:03.517870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 21882 MB memory:  -> device: 3, name: GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 15:23:05.765867: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n",
      "2022-02-03 15:23:07.964377: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 - 5s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5625 - model_1_acc: 0.9132 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 5s/epoch - 38ms/sample\n",
      "Epoch 2/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 635ms/epoch - 4ms/sample\n",
      "Epoch 3/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 631ms/epoch - 4ms/sample\n",
      "Epoch 4/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 607ms/epoch - 4ms/sample\n",
      "Epoch 5/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 601ms/epoch - 4ms/sample\n",
      "Epoch 6/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 596ms/epoch - 4ms/sample\n",
      "Epoch 7/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 592ms/epoch - 4ms/sample\n",
      "Epoch 8/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 620ms/epoch - 4ms/sample\n",
      "Epoch 9/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 750ms/epoch - 5ms/sample\n",
      "Epoch 10/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 707ms/epoch - 5ms/sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-02-03 15:23:22,111]\u001b[0m Trial 0 failed, because the objective function returned nan.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan nan 0.59 0.9469318\n",
      "Train size :(194, 128, 128, 3), Test size:(100, 128, 128, 3)\n",
      "Train2 size :(144, 128, 128, 3), val size:(50, 128, 128, 3)\n",
      "Train on 144 samples, validate on 50 samples\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 15:23:23.567484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4094 MB memory:  -> device: 0, name: GeForce RTX 3090, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
      "2022-02-03 15:23:23.568412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 4096 MB memory:  -> device: 1, name: GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\n",
      "2022-02-03 15:23:23.569288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 21882 MB memory:  -> device: 2, name: GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2022-02-03 15:23:23.570156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 21882 MB memory:  -> device: 3, name: GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 15:23:24.447225: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 - 2s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5625 - model_1_acc: 0.8612 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 2s/epoch - 15ms/sample\n",
      "Epoch 2/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 701ms/epoch - 5ms/sample\n",
      "Epoch 3/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 741ms/epoch - 5ms/sample\n",
      "Epoch 4/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 745ms/epoch - 5ms/sample\n",
      "Epoch 5/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 715ms/epoch - 5ms/sample\n",
      "Epoch 6/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 707ms/epoch - 5ms/sample\n",
      "Epoch 7/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 712ms/epoch - 5ms/sample\n",
      "Epoch 8/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 703ms/epoch - 5ms/sample\n",
      "Epoch 9/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 587ms/epoch - 4ms/sample\n",
      "Epoch 10/100\n",
      "144/144 - 1s - loss: nan - Family_Classifier_loss: nan - model_1_loss: nan - Family_Classifier_acc: 0.5903 - model_1_acc: 0.9465 - val_loss: nan - val_Family_Classifier_loss: nan - val_model_1_loss: nan - val_Family_Classifier_acc: 0.6000 - val_model_1_acc: 0.9456 - lr: 0.0010 - 682ms/epoch - 5ms/sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 15:23:34.834079: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-02-03 15:23:34.834350: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-02-03 15:23:34.834500: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-02-03 15:23:34.834915: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-02-03 15:23:34.835174: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-02-03 15:23:34.839236: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-02-03 15:23:34.919909: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-02-03 15:23:34.923263: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-02-03 15:23:34.939131: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "\u001b[33m[W 2022-02-03 15:23:35,206]\u001b[0m Trial 1 failed, because the objective function returned nan.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan nan 0.59 0.9469318\n",
      "Train size :(194, 128, 128, 3), Test size:(100, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  # Specify an invalid GPU device\n",
    "    for index in range(100):\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "        print(\"{} th trial\".format(index))\n",
    "        study = optuna.create_study()\n",
    "        study.optimize(objective, n_trials=100)\n",
    "        df = study.trials_dataframe()\n",
    "        df.to_csv(\"./Results/result_20220202/VAE_optuna_tuning_result_20210202_seed_42_trial{}.csv\".format(index))\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
