{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53cf593",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-13T11:01:41.393Z"
    }
   },
   "outputs": [],
   "source": [
    "## Libraries need to calculate Moprho-VAE\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import cv2  \n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.backend import set_session\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from plotly.offline import init_notebook_mode\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functions import *\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101626ee",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-13T11:01:23.236Z"
    }
   },
   "outputs": [],
   "source": [
    "## GPU settings \n",
    "## This code is written in Tensorflow v1\n",
    "### if you want to run this notebook, you should prepare GPU.\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(\n",
    "        visible_device_list=\"0\", # specify GPU number\n",
    "        allow_growth=True\n",
    "    )\n",
    ")\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b2a35",
   "metadata": {},
   "source": [
    "# Load images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e862473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load figures \n",
    "X, y = load_data()\n",
    "filelist = pd.read_csv(\"./new_Mandible_check.csv\", encoding=\"SHIFT-JIS\")\n",
    "\n",
    "## Split data into train and test data.\n",
    "X_train, y_train,Y_train, X_test, y_test , Y_test, group_train, group_test =  make_train_test(X,y,seed = test_seed)\n",
    "## Split train data into val  and train data\n",
    "X_train_2, y_train_2,Y_train_2, X_val, y_val ,Y_val, val_seed, group_train_2, group_val = \\\n",
    "make_val_train(X_train,y_train,group_train,seed = val_seed)\n",
    "print(val_seed)\n",
    "\n",
    "num_to_name ={0: 'Cercopithecidae',\n",
    " 1: 'Cebidae',\n",
    " 2: 'Lemuridae',\n",
    " 3: 'Atelidae',\n",
    " 4: 'Hylobatidae',\n",
    " 5: 'Homonidae',\n",
    " 6: 'Phocidae'}\n",
    "\n",
    "y_name= np.array(pd.Series(y).replace(num_to_name))\n",
    "\n",
    "\n",
    "print(\"train\")\n",
    "print(group_train)\n",
    "print(\"test\")\n",
    "print(group_test) \n",
    "print(\"val\")\n",
    "print(group_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f094db",
   "metadata": {},
   "source": [
    "# Model setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model setting \n",
    "####  this csv file includes 10 tuned models.\n",
    "#### Best model is 7-th model. \n",
    "arch_list = pd.read_csv('./architecture_list.csv')\n",
    "num = 7\n",
    "### ration of Reconstruction loss and Classification losss\n",
    "### in this paper we set alpha = 0.1\n",
    "## If you set alpha = 0 this matches VAE. \n",
    "alpha = 0.1 \n",
    "### the dimension of latent space Î¶\n",
    "latent_dim = 3\n",
    "\n",
    "### create Morpho-VAE model\n",
    "model, z_mean, z_log_var, encoder, decoder, Classifier = create_model(arch_list.iloc[num,0], arch_list.iloc[num,1], list((arch_list.iloc[num,2:7]).astype(int)),3)\n",
    "\n",
    "optimizer = arch_list.iloc[num,8]\n",
    "model.compile(optimizer=optimizer, \n",
    "          loss = ['categorical_crossentropy',vae_loss], \n",
    "          loss_weights = [alpha, 1 - alpha],\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a8dad",
   "metadata": {},
   "source": [
    "## load Morpho-VAE's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We load the weights of Morpho-VAE.\n",
    "## If you want to train Morpho-VAE, ignore this cell and move to 2.2 train model section.\n",
    "test_seed = 230\n",
    "val_seed = 42\n",
    "\n",
    "    \n",
    "encoder_path = glob.glob(\"./WEIGHTS/Publish/*/{0}/encoder_*\".format(test_seed))[0]\n",
    "decoder_path = glob.glob(\"./WEIGHTS/Publish/*/{0}/decoder_*\".format(test_seed))[0]\n",
    "Classifier_path = glob.glob(\"./WEIGHTS/Publish/*/{0}/Classifier_*\".format(test_seed))[0]\n",
    "model_path = glob.glob(\"./WEIGHTS/Publish/*/{0}/model_*\".format(test_seed))[0]\n",
    "\n",
    "encoder.load_weights(encoder_path)\n",
    "decoder.load_weights(decoder_path)\n",
    "Classifier.load_weights(Classifier_path)\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40324a82",
   "metadata": {},
   "source": [
    "## load VAE's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a4bc2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## VAE\n",
    "test_seed = 227\n",
    "\n",
    "arch_list = pd.read_csv('/home/tsutsumi/BONE/MORPHO-VAE/CODE/architecture_list.csv')\n",
    "num = 4\n",
    "\n",
    "VAE_model, z_mean, z_log_var, VAE_encoder, VAE_decoder, VAE_Classifier = create_model(arch_list.iloc[num,0], arch_list.iloc[num,1], list((arch_list.iloc[num,2:7]).astype(int)),3)\n",
    "\n",
    "\n",
    "encoder_path = glob.glob(\"./WEIGHTS/Publish/20220211/{0}/encoder_*\".format(test_seed))[0]\n",
    "decoder_path = glob.glob(\".WEIGHTS/Publish/20220211/{0}/decoder_*\".format(test_seed))[0]\n",
    "Classifier_path = glob.glob(\"./WEIGHTS/Publish/20220211/{0}/Classifier_*\".format(test_seed))[0]\n",
    "model_path = glob.glob(\"./WEIGHTS/Publish/20220211/{0}/model_*\".format(test_seed))[0]\n",
    "\n",
    "VAE_encoder.load_weights(encoder_path)\n",
    "VAE_decoder.load_weights(decoder_path)\n",
    "VAE_Classifier.load_weights(Classifier_path)\n",
    "VAE_model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a2aa84",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6afe56",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that if you want to train Morpho-VAE model, GPU enviroments is needed.\n",
    "CPU environments will cost you a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be122025",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_2,\n",
    "                      [Y_train_2, X_train_2],\n",
    "                      epochs=100,\n",
    "                      batch_size=10,\n",
    "                      validation_data=(X_val,[Y_val,X_val]),\n",
    "                      callbacks = callbacks,\n",
    "                     verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02809ab6",
   "metadata": {},
   "source": [
    "# Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e617aabd",
   "metadata": {},
   "source": [
    "## Cluster Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177cb2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Morpho-VAE\n",
    "X_predict_morphoVAE = encoder.predict(X)\n",
    "plot_3d(X_predict_morphoVAE, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44dcc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VAE\n",
    "X_predict_VAE = VAE_encoder.predict(X)\n",
    "plot_3d(X_predict_VAE, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA\n",
    "d1, d2, d3, d4 = X.shape\n",
    "X_flatten = X.reshape((d1, -1))\n",
    "pca = PCA(n_components=3, svd_solver='arpack')\n",
    "pca.fit(X_flatten)\n",
    "feature = pca.transform(X_flatten)\n",
    "\n",
    "plot_3d(feature, y_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb75fe",
   "metadata": {},
   "source": [
    "## Reconstructiong and Generating Images from Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec01680",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The value of PC3\n",
    "zi = 0\n",
    "## The size of rectangle\n",
    "size = 10\n",
    "\n",
    "x_predict = X_predict_morphoVAE.copy()\n",
    "xyz = np.mean(x_predict, axis = 0)[:,np.newaxis]+ zi * pca.components_[2][:,np.newaxis] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e71a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## latent space and PCA plane\n",
    "plot_latent_and_PCAplane(x_predict, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a24ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA plane\n",
    "pca = PCA()\n",
    "feature = pca.fit(x_predict)\n",
    "feature = pca.transform(x_predict)\n",
    "\n",
    "plot_2d(feature,y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reconst grid images\n",
    "reconst_grid_images(size,xyz,digit_size = 128,THR = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b8dcb",
   "metadata": {},
   "source": [
    "## Visual Explanation of the Basis for Class Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea5285",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,10))\n",
    "for family_num in [5]:\n",
    "    for idx in range(np.where([y_test == family_num])[1].shape[0]):\n",
    "        Num = np.where([y_test == family_num])[1][idx]\n",
    "        family = sorted(set(y_name))[np.argmax(Y_train[Num])]\n",
    "        for color,i,ch in zip(['G','B','R'],[0,1,2],[1,2,0]):\n",
    "            ax = fig.add_subplot(np.where([y_test == family_num])[1].shape[0], 3, idx * 3+i +1)\n",
    "            ax.axes.xaxis.set_visible(False)\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "            x, A,act_map = score_cam(num = Num , layer_name = '{}_conv_4'.format(color))\n",
    "            A = cv2.resize(A,(128,128))\n",
    "            A = np.maximum(A, 0)     \n",
    "            A /= np.max(A)      \n",
    "            ax.imshow(A,cmap='GnBu')\n",
    "            ax.imshow(x[0,:,:,ch], alpha = 0.1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa9fb12",
   "metadata": {},
   "source": [
    "## Reconstruction from Cropped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a23fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'M012'\n",
    "size = 25\n",
    "\n",
    "NAME = '{}.png'.format(name)\n",
    "CROPPED = '../Fixed_figure/Crop_fig_{}/RGB/{}'.format(size,NAME)\n",
    "NOT_CROPPED = '../New-RGB/{}'.format(NAME)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(cv2.imread(NOT_CROPPED))\n",
    "plt.subplot(132)\n",
    "plt.imshow(cv2.imread(CROPPED))\n",
    "plt.subplot(133)\n",
    "plt.imshow(decoder.predict(encoder.predict(cv2.imread(CROPPED)[np.newaxis]/255))[0])\n",
    "print(\"True: {} , Predict: {}\".format(y_test[group_test == name][0],np.argmax(Classifier.predict(cv2.imread(CROPPED)[np.newaxis]/255))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLC-CPU] *",
   "language": "python",
   "name": "conda-env-DLC-CPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
